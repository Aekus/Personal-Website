<html>
<head>
<script src="http://code.jquery.com/jquery.min.js"> </script>
<script src="proj3/js/chessboard-1.0.0.js"> </script>
    <script src="proj3/js/chess.js"> </script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-167856456-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-167856456-1');
</script>
    
<title> Creating a Chess Engine </title>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="proj3/css/chessboard-1.0.0.css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
    <div id = "page">
    <section id="header">
    <div id="menu">
        <nav id="Main Menu" role="navigation">
            <ul id = "navigation_list">
				<li id="about_me"><a href="index.html"  id="about_link">About me</a></li>
                <li id="projects"><a href="projects.html" class="active" id="projects_link">Projects</a></li>
            </ul>
        </nav>
    </div>
    </section>
        <hr>
    <section id="main">
    <h1 class="project_title"> Creating a Chess Engine </h1>
        <div class="icon"><a href="https://github.com/Aekus/Virus-Modelling"><img src="pics/githubwidget.svg" id="github_link"/> </a> </div>
        <h2 class="project_subheader"> Introduction </h2>
        <p class="text">
            In the past month or so, I've gotten into chess quite a bit on websites like <a href="https://www.chess.com/" class="in-text_link">Chess.com</a> and <a href="https://lichess.org/" class="in-text_link"> Lichess.org</a> Usually, after blundering for an entire game, I visit the analysis section to see where exactly I went wrong with the hope of learning from my mistakes. This rarely ever works, but the past few times I've wandered into the analysis section, something else has piqued my interest. Both <a href="https://www.chess.com/" class="in-text_link">Chess.com</a> and <a href="https://lichess.org/" class="in-text_link"> Lichess.org </a> use incredibly strong chess engines for their analysis (the former uses Stockfish 10 by default while the latter uses the newer Stockfish 11.) For some background, since 1995 when Deep Blue beat World Champion Garry Kasparov in a 6 game series, computers have been considered superior to even the greatest grandmasters. Realizing there was no hope for me as a chess player, I took inspiration from Kevin Durant and thought "if you can't beat them, might as well join them." So I took on the challenge of building my own chess engine. Evidently, there is no way I will reach the levels of Stockfish (due to both the mechanical constraints of running everything off of a 4-year-old Dell XPS and the shear difference in knowledge and experience). Still, I want to build something that I can be proud of and learn something along the way.  
        </p>
        <h2 class="project_subheader"> Tools </h2>
        <p class="text">
            Before going over the AI itself, there are some other requirements. At the most basic level, there's the language that I will code in. While C++ is the obvious choice for speed, I'm most familiar with Java, so I chose to write the engine in Java. Next, we would need some way to represent the game of chess (the flipping of turns, the chess pieces, the board itself). There also must be a way of representing moves and extracting a list of moves for any given position. Finally, there would have to be some standardizations such as reading/writing of Forsyth-Edwards Notation (FEN) and Portable Game Notation (PGN). If this were a game like checkers or tic-tac-toe, I would be inclined to coding this myself, but moves in chess are a programming nightmare. For starters, there are 6 different types of pieces which move in 6 different ways. Next, there are exceptions to those moves such as pawns capturing diagonally, knights being able to skip over pieces, castling, en-passant and pawn promotion. There are also rules such as 50-move rule, insufficient material, stalemate, and threefold repetition that only add to the complexity. I wanted to focus the majority of my effort on the engine itself, so I decided to use <a href="http://www.chesspresso.org/" class="in-text_link"> Chesspresso</a>, an open-source java library. Unfortunately, theres not much documentation available and there's not many implementations of Chesspresso on the internet, so I spent quite a few hours reading through the relevant classes myself. Chesspresso fulfills all the above requirements and does so quite efficiently. Leading chess engines all use some sort of bitboard, which is a representation of the chess board, pieces, and moves as bits. This significantly reduces the time complexity of determining valid moves.
        </p>
        <h2 class="project_subheader"> Minimax and Alpha-Beta Pruning </h2>
        <p class="text">
            Now comes the more interesting part. For two player zero-sum games, game trees are the most succesful abstraction for AIs. Neural nets have also been shown to work in some cases, but the leading chess engines all use some sort of game tree as the backbone of their program. Within game trees, the most commonly used algorithm is Minimax. Minimax is a type-A search algorithm which evaluates all positions up to a certain depth level. Type-A simply means that every single (useful) node is searched up to a certain depth, after which no node is searched. The reason I say "useful" will soon become apparent. More specifically, minimax evaluates all leaf nodes using a heuristic function that assigns a score to each position. The greater the score the better the position for one player and worse for the other, while the converse is true as well. Beginning at the depth <i>d</i>, either the maximum or minimum score is chosen for each node in <i>d - 1</i>. This repeats at each subsequent depth level, flipping maximum or minimum each time such that at <i>d = 0</i>, if it is white's turn to play the maximizing node will be chosen while if it's blacks turn the minimizing node with be chosen. This is rather confusing to convey in words, so see <a href="https://www.baeldung.com/java-minimax-algorithm" class="in-text_link">here</a> for visualizations.  
        </p>
        <p class="text">
            I say that every useful node will be searched since we will be implementing alpha-beta pruning, an optimization of Minimax. In short, alpha-beta pruning takes advantage of the fact that when searching for a minimizing or maximizing node, there might be situations wherein no matter what the state of a nephew node is, it's parent will never be chosen assuming optimal play. Then, we can "prune" that nephew, its children, grandchildren and so on by ignoring them in our search. For a better description and visualization of this algorithm, see <a href="https://www.javatpoint.com/ai-alpha-beta-pruning" class="in-text_link">here</a> The power of alpha-beta pruning is immense. For reference, in one of my implementations, without alpha-beta pruning I searched 243,000 leaf nodes at depth 4, whereas with alpha-beta pruning that number was reduced to just 65,000 leaf nodes at a depth level of 5. 
        </p>
        <h2 class="project_subheader"> Heuristic Function </h2>
        <p class="text">
            The implementation of minimax is roughly the same universally, so the most important part of the algorithm is likely the evaluation heuristic. Ultimately, I wanted to make the engine 'mine' so while there is plenty of literature online about chess heuristics, I chose to create my own. The benefit of a Type-A search algorithm, is that my engine can guarantee forced wins (meaning a checkmate in less than <i>n</i> moves no matter what the opponent plays) when the number of moves is less than the search depth. In the vast majority of chess positions, however, there are no forced wins. Thus, a heuristic function is a sort of guide for the direction in which the game should develop for my side. 
        </p>
        <p class="text">
            Unfortunately, I wasn't able to access the bitboard directly from the Chesspresso .jar file, so in coming up with my heuristic, I had to iterate over the entire board, making my implementation less than ideal. Without going into too much depth about the specific numbers I chose, I want to explain the main aspects of my heuristic. Most basically, I assigned each piece on the board a value: 100 for pawns, 300 for knights, 325 for bishops, 500 for rooks, and 900 for queens. The ratios between these numbers are fairly standard and agreed upon in the chess community. Next, I modified these values slightly based on position parameters. For pawns, I increased the value of those closer to the center and further along the board. For knights, I valued those closer to the center of the board higher, which I calculated using euclidean distance. Knights in a 4x4 grid in the center of the chessboard have a maximum of 8 possible moves, while those on edges or corners have less moves. For bishops, I did the same since bishops closer to the center have more diagonals and possible moves. For rooks, I found that there isn't much of an advantage in placing a rook in the center of a board since it's often the king's primary defender and is used in combination with the other rook and queen to launch 'stacked' attacks. Hence, I left the positional score of the rook the same everywhere on the board. Likewise, I found that the Queen's movement is quite varied in chess games. While a central position would increase attack threats, the queen is also much more valuable than the minor pieces and would thus be more vulnerable to enemy attacks in the center. Due to this complexity, I chose to leave the Queen's score constant. Finally, for the King, I rewarded safety, thus providing a point bonus of 100 points for a king side castle and 50 points for a queen side castle.
        </p>
        <p class="text">
            In additional to positional parameters, there are special bonuses that I added. I added a significant bonus for pass pawns due to the promotion threat. For bishops, I added a bonus for the openness of their main diagonal defined by the number of total pawns blocking their path. The more open the diagonal, the more squares are being controlled by a bishop. Likewise, for rooks I added an open lane bonus that is given if there are no pawns blocking a rook's vertical lane. Finally, for the king, I added a protection bonus if there are 3 or less unoccupied squares around it. With my heuristic and algorithm complete, it's time to run our first game of our engine playing itself.
        </p>
        <p class="text">
            I wanted to make my engine as interactive to readers as possible, so I tried hosting it on this website. Then, I realized that github pages, where this website is hosted, only supports static pages, meaning I had to run everything clientside. I then tried translating my engine in JavaScript using the <a href="https://github.com/jhlywa/chess.js/blob/master/README.md" class="in-text_link"> chess.js</a> library for move generation. After implementing minimax, I ran the engine only to find out that my maximum search depth was 2, and at search depth 3, minimax takes >10 seconds. At search depth 4, the browser crashed and so did my hopes. And this was before implementing a proper heuristic function (at the time, I was randomly generating a heuristic). I'm still not sure why my implementation is so slow since chess.js also seems to be using bitboards, but after 2 days of tiddling with all parts of my code, I decided to stick with my old engine. I compromised on user-interactivity and decided to import the PGN from my engine into the chess.js library and use the <a href="https://chessboardjs.com" class="in-text_link">chessboard.js</a> library to visualize my games in JavaScript. By the way, I must say that the interface and documentation for chessboard.js is incredibly easy-to-use and well-written.   
        </p>
        <p class="text">
            Here is the game I promised to show you two paragraphs ago:
        </p>
        <div id="game_area">
        <div id="chessboard">
        </div>
        <button id="prevButton" onclick="prevMove(pgn1)">
            <
        </button>
        <button id="startbutton" onclick="playGame(pgn1)">
            Play
        </button>
        <button id="nextButton" onclick="nextMove(pgn1)">
            >
        </button>
        </div>
        <p class="text">
            It doesn't take more than a few seconds of cursory analysis to see that this game was bad. That being said,
            the moves made are definitely better than random and the engine seems to understand piece value to a certain degree. The opening played is very unusual and technically unsound according to stockfish. There are also random sacrifices that lose material and don't seem to provide any positional advantage. Simple two-move tactics such as 13. Qc3+ by black to fork the rook in check are missed and the endgame is unnecessarily drawn out. If I were to guess the elo for the engine, I would guess maybe around 600-700.  
        </p>
        <p class="project_subheader"> Iterative Deepening and Shallow Move Ordering</p>
        <p class="text">
        The first improvement we can make to our existing minimax structure is to implement a different search strategy called iterative deepening. Normally, minimax is implemented recursively as a DFS. There are, however, many benefits of a BFS. For one, knowing the 'value' of all moves at depth <i>d - 1</i> could provide useful feedback for further search, such as where/how to prune and maximize efficiency. The implementation of BFS, however, would require the use of a stack and since the branching factor of our current game tree is massive (~30), BFS would be very memory-intensive. The in-between of DFS and BFS is iterative deepening. Quite simply, iterative deepening means running the normal DFS at increasing levels of depth. Initially, such an idea would seem counterintuitive. Calling the minimax algorithm at incrementing depths would be redundant since <i>d = 1</i> will be searched <i>n</i> times, <i>d = 2</i> will be searched <i>n - 1</i> times and so on. This is in fact true, but since the branching factor of the minimax structure is so large, each successive search requires roughly <i>b - 1</i> more computing power than the previous search where <i>b</i> is the branching factor. Since the number of nodes at each depth form a geometric series, this can be proven to be true. There is also another benefit to this algorithm. At various stages of the game and different positions, the branching factor varies (in closed positions and certain king and pawn endgames the branching factor can be low ~10, whereas for very open positions where the majority of material is still on the board, I've seen the branching factor be close to 70). Thus, it would be unwise to have a constant depth. Using iterative deepening allows a program to store the best move at <i>d - 1</i> in case going one ply deeper would be too computationally intensive.     
        </p>
        <p class="text">
        Once iterative deepening is implemented, we can look to take advantage of it by implementing shallow move ordering. Begininning at depth = 1, we use minimax to evaluate each move for the current player. Normally, such information would go to waste as we only care about the best move, however, we can take advantage of this extra information by ordering the moves from best to worst for the next depth level. Once again, the moves are ordered according to their new evaluation and the process is repeated. The benefit of ordering moves has to do with how alpha-beta pruning works. alpha and beta converge faster when the better moves appear earlier, meaning that the number of branches that are pruned also increases. I tested out move ordering by counting the number of searched nodes when the moves were ordered and then the number when the ordering was reversed (worst to best) and found that the number of nodes searched with reverse ordering is more than double.
        </p>
        <p class="project_subheader"> Quiescent Search </p>
        <p class="text">
        Implementing iterative deepening and shallow move ordering doesn't change how positions are evaluated, it simply makes search faster. In chess, like many games, there is a horizon effect at play with limited searches. Since engines can only see to a certain depth, they will consider the best situation at that depth even if such a position is horrible just one ply further. Take, for instance, a simple example. Suppose our engine can only see until depth 1. Then, the best move might be Queen takes Bishop. In the engine's figurative mind, a bishop has been won, a significant gain from our current point of view. Suppose that the bishop is defended by a pawn, now such a move is disastrous as the opponent can easily play pawn takes queen and now the opponent is up instead. Thus, we have to have some sort of secondary search that explores nodes beyond our maximum depth according to 
        </p>
    </section>
    </div>
    </body>
    <script src="js/index.js"> </script>
</html>